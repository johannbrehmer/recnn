{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext cython\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython -f -+ -I/home/jb6504/tools/fastjet-3.3.0/../fastjet-build/include --link-args=-Wl,-rpath,/home/jb6504/tools/fastjet-3.3.0/../fastjet-build/lib -lm -L/home/jb6504/tools/fastjet-3.3.0/../fastjet-build/lib -lfastjettools -lfastjet\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "np.import_array()\n",
    "\n",
    "from libcpp.pair cimport pair\n",
    "from libcpp.vector cimport vector\n",
    "\n",
    "cdef extern from \"/home/jb6504/learning_substructure/recnn/notebooks/fj.cc\":\n",
    "    void fj(vector[double]& a, \n",
    "            vector[vector[int]]& trees, \n",
    "            vector[vector[double]]& contents, \n",
    "            vector[double]& masses, \n",
    "            vector[double]& pts, \n",
    "            double R, int jet_algorithm)\n",
    "    \n",
    "cpdef cluster(np.ndarray[np.double_t, ndim=2, mode=\"c\"] a, \n",
    "              R=0.3, jet_algorithm=0):\n",
    "    cdef vector[double] v\n",
    "    cdef vector[vector[int]] trees\n",
    "    cdef vector[vector[double]] contents\n",
    "    cdef vector[double] masses\n",
    "    cdef vector[double] pts \n",
    "    for value in a.ravel():\n",
    "        v.push_back(value)\n",
    "    \n",
    "    fj(v, trees, contents, masses, pts, R=R, jet_algorithm=jet_algorithm)\n",
    "    jets = []\n",
    "    \n",
    "    for tree, content, mass, pt in zip(trees, contents, masses, pts):\n",
    "        tree = np.array([e for e in tree]).reshape(-1, 2)\n",
    "        content = np.array([e for e in content]).reshape(-1, 4)\n",
    "        jets.append((tree, content, mass, pt))\n",
    "        \n",
    "    return jets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.10/06\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from rootpy.vector import LorentzVector\n",
    "from recnn.preprocessing import _pt\n",
    "\n",
    "# Preprocessing algorithm:\n",
    "# 1. j = the highest pt anti-kt jet (R=1)\n",
    "# 2. run kt (R=0.3) on the constituents c of j, resulting in subjets sj1, sj2, ..., sjN\n",
    "# 3. phi = sj1.phi(); for all c, do c.rotate_z(-phi)\n",
    "# 4. bv = sj1.boost_vector(); bv.set_perp(0); for all c, do c.boost(-bv)\n",
    "# 5. deltaz = sj1.pz - sj2.pz; deltay = sj1.py - sj2.py; alpha = -atan2(deltaz, deltay); for all c, do c.rotate_x(alpha)\n",
    "# 6. if sj3.pz < 0: for all c, do c.set_pz(-c.pz)\n",
    "# 7. finally recluster all transformed constituents c into a single jet (using kt or anti-kt? r?)\n",
    "\n",
    "def preprocess(jet, output=\"kt\", colinear_splits=0, trimming=0.0):\n",
    "    jet = copy.deepcopy(jet)\n",
    "    constituents = jet[\"content\"][jet[\"tree\"][:, 0] == -1] \n",
    "    \n",
    "    for i in range(colinear_splits):\n",
    "        #j = np.random.randint(len(constituents))\n",
    "        j = np.argmax([_pt(c) for c in constituents])\n",
    "        v = LorentzVector(constituents[j])\n",
    "        \n",
    "        eps = np.random.rand()\n",
    "        \n",
    "        p1 = LorentzVector()\n",
    "        p2 = LorentzVector()\n",
    "        p1.set_pt_eta_phi_m(v.pt() * eps, v.eta(), v.phi(), v.m() * eps ** 0.5)\n",
    "        p2.set_pt_eta_phi_m(v.pt() * (1. - eps), v.eta(), v.phi(), 0.0)\n",
    "\n",
    "        constituents[j][0] = p1.px\n",
    "        constituents[j][1] = p1.py\n",
    "        constituents[j][2] = p1.pz\n",
    "        constituents[j][3] = p1.e\n",
    "        \n",
    "        constituents = np.vstack([constituents, \n",
    "                                  np.array([[p2.px, p2.py, p2.pz, p2.e]])])\n",
    "\n",
    "    # run kt (R=0.3) on the constituents c of j, resulting in subjets sj1, sj2, ..., sjN\n",
    "    subjets = cluster(constituents, R=0.3, jet_algorithm=0)\n",
    "    \n",
    "    # trimming\n",
    "    if trimming > 0.0:\n",
    "        subjets = [(tree, content, mass, pt) for tree, content, mass, pt in subjets if pt > trimming * jet[\"pt\"]]\n",
    "    else:\n",
    "        subjets = [(tree, content, mass, pt) for tree, content, mass, pt in subjets]\n",
    "    \n",
    "    # phi = sj1.phi()\n",
    "    # for all c, do c.rotate_z(-phi)\n",
    "    v = subjets[0][1][0]\n",
    "    v = LorentzVector(v)\n",
    "    phi = v.phi()\n",
    "    \n",
    "    for _, content, _, _ in subjets:\n",
    "        for i in range(len(content)):\n",
    "            v = LorentzVector(content[i])\n",
    "            v.rotate_z(-phi)\n",
    "            content[i, 0] = v[0]\n",
    "            content[i, 1] = v[1]\n",
    "            content[i, 2] = v[2]\n",
    "            content[i, 3] = v[3]\n",
    "            \n",
    "    # bv = sj1.boost_vector()\n",
    "    # bv.set_perp(0)\n",
    "    # for all c, do c.boost(-bv)\n",
    "    v = subjets[0][1][0]\n",
    "    v = LorentzVector(v)\n",
    "    bv = v.boost_vector()\n",
    "    bv.set_perp(0)\n",
    "    \n",
    "    for _, content, _, _ in subjets:        \n",
    "        for i in range(len(content)):\n",
    "            v = LorentzVector(content[i])\n",
    "            v.boost(-bv)\n",
    "            content[i, 0] = v[0]\n",
    "            content[i, 1] = v[1]\n",
    "            content[i, 2] = v[2]\n",
    "            content[i, 3] = v[3]\n",
    "    \n",
    "    # deltaz = sj1.pz - sj2.pz\n",
    "    # deltay = sj1.py - sj2.py\n",
    "    # alpha = -atan2(deltaz, deltay)\n",
    "    # for all c, do c.rotate_x(alpha)\n",
    "    if len(subjets) >= 2:\n",
    "        deltaz = subjets[0][1][0, 2] - subjets[1][1][0, 2]\n",
    "        deltay = subjets[0][1][0, 1] - subjets[1][1][0, 1]\n",
    "        alpha = -np.arctan2(deltaz, deltay)\n",
    "\n",
    "        for _, content, _, _ in subjets:\n",
    "            for i in range(len(content)):\n",
    "                v = LorentzVector(content[i])\n",
    "                v.rotate_x(alpha)\n",
    "                content[i, 0] = v[0]\n",
    "                content[i, 1] = v[1]\n",
    "                content[i, 2] = v[2]\n",
    "                content[i, 3] = v[3]\n",
    "    \n",
    "    # if sj3.pz < 0: for all c, do c.set_pz(-c.pz)\n",
    "    if len(subjets) >= 3 and subjets[2][1][0, 2] < 0:\n",
    "        for _, content, _, _ in subjets:\n",
    "            for i in range(len(content)):\n",
    "                content[i, 2] *= -1.0\n",
    "                \n",
    "    # finally recluster all transformed constituents c into a single jet \n",
    "    constituents = []\n",
    "    \n",
    "    for tree, content, _, _ in subjets:\n",
    "        constituents.append(content[tree[:, 0] == -1])\n",
    "        \n",
    "    constituents = np.vstack(constituents)\n",
    "    \n",
    "    if output == \"anti-kt\":\n",
    "        subjets = cluster(constituents, R=100., jet_algorithm=1)\n",
    "    elif output == \"kt\":\n",
    "        subjets = cluster(constituents, R=100., jet_algorithm=0)\n",
    "    elif output == \"cambridge\":\n",
    "        subjets = cluster(constituents, R=100., jet_algorithm=2)\n",
    "    else:\n",
    "        raise\n",
    "    \n",
    "    jet[\"tree\"] = subjets[0][0]\n",
    "    jet[\"content\"] = subjets[0][1]\n",
    "    \n",
    "    v = LorentzVector(jet[\"content\"][0])\n",
    "    jet[\"phi\"] = v.phi()\n",
    "    jet[\"eta\"] = v.eta()\n",
    "    jet[\"energy\"] = v.E()\n",
    "    jet[\"mass\"] = v.m()\n",
    "    jet[\"pt\"] = v.pt()\n",
    "    jet[\"root_id\"] = 0\n",
    "    \n",
    "    return jet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recnn.preprocessing import randomize\n",
    "from recnn.preprocessing import sequentialize_by_pt\n",
    "\n",
    "f = \"scratch/jb6504/data/w-vs-qcd/anti-kt/antikt-train-pileup25.pickle\"\n",
    "# f = \"scratch/jb6504/data/w-vs-qcd/anti-kt/antikt-test-pileup25.pickle\"\n",
    "\n",
    "# f = \"../data/w-vs-qcd/anti-kt/antikt-train.pickle-py27\"\n",
    "# f = \"../data/w-vs-qcd/anti-kt/antikt-test.pickle-py27\"\n",
    "\n",
    "# f = \"../data/w-vs-qcd/anti-kt/antikt-soft-train.pickle\"\n",
    "# f = \"../data/w-vs-qcd/anti-kt/antikt-soft-test.pickle\"\n",
    "\n",
    "fd = open(f, \"rb\")\n",
    "X, y = pickle.load(fd)\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. anti-kt highest pt -> preprocessing -> anti-kt\n",
    "X_ = []\n",
    "\n",
    "for j in X:\n",
    "    X_.append(preprocess(j, output=\"anti-kt\"))\n",
    "    \n",
    "fd = open(\"%s-anti-kt\" % f, \"wb\")\n",
    "pickle.dump((X_, y), fd, protocol=2)\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. anti-kt highest pt -> preprocessing -> kt\n",
    "X_ = []\n",
    "\n",
    "for j in X:\n",
    "    X_.append(preprocess(j, output=\"kt\"))\n",
    "    \n",
    "fd = open(\"%s-kt\" % f, \"wb\")\n",
    "pickle.dump((X_, y), fd, protocol=2)\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. anti-kt highest pt -> preprocessing -> random\n",
    "X_ = []\n",
    "\n",
    "for j in X:\n",
    "    X_.append(randomize(preprocess(j, output=\"anti-kt\")))\n",
    "    \n",
    "fd = open(\"%s-random\" % f, \"wb\")\n",
    "pickle.dump((X_, y), fd, protocol=2)\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. anti-kt highest pt -> preprocessing -> seq by pt\n",
    "X_ = []\n",
    "\n",
    "for j in X:\n",
    "    X_.append(sequentialize_by_pt(preprocess(j, output=\"anti-kt\"), reverse=False))\n",
    "    \n",
    "fd = open(\"%s-seqpt\" % f, \"wb\")\n",
    "pickle.dump((X_, y), fd, protocol=2)\n",
    "fd.close()\n",
    "\n",
    "X_ = []\n",
    "\n",
    "for j in X:\n",
    "    X_.append(sequentialize_by_pt(preprocess(j, output=\"anti-kt\"), reverse=True))\n",
    "    \n",
    "fd = open(\"%s-seqpt-reversed\" % f, \"wb\")\n",
    "pickle.dump((X_, y), fd, protocol=2)\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. anti-kt highest pt -> preprocessing -> cambridge\n",
    "X_ = []\n",
    "\n",
    "for j in X:\n",
    "    X_.append(preprocess(j, output=\"cambridge\"))\n",
    "    \n",
    "fd = open(\"%s-cambridge\" % f, \"wb\")\n",
    "pickle.dump((X_, y), fd, protocol=2)\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. anti-kt highest pt -> preprocessing -> kt-colinear1\n",
    "X_ = []\n",
    "\n",
    "for j in X:\n",
    "    X_.append(preprocess(j, output=\"kt\", colinear_splits=10))\n",
    "    \n",
    "fd = open(\"%s-kt-colinear10-max\" % f, \"wb\")\n",
    "pickle.dump((X_, y), fd, protocol=2)\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trimmed data\n",
    "f = \"../data/w-vs-qcd/anti-kt/antikt-train.pickle-py27\"\n",
    "# f = \"../data/w-vs-qcd/anti-kt/antikt-test.pickle-py27\"\n",
    "\n",
    "fd = open(f, \"rb\")\n",
    "X, y = pickle.load(fd)\n",
    "fd.close()\n",
    "\n",
    "# anti-kt highest pt -> preprocessing(trimming=0.05) -> kt\n",
    "X_ = []\n",
    "\n",
    "for j in X:\n",
    "    X_.append(preprocess(j, output=\"anti-kt\", trimming=0.05))\n",
    "    \n",
    "fd = open(\"%s-anti-kt-trimmed\" % f, \"wb\")\n",
    "pickle.dump((X_, y), fd, protocol=2)\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from recnn.preprocessing import sequentialize_by_pt\n",
    "from recnn.preprocessing import randomize\n",
    "\n",
    "# random trees, asc-pt, desc-pt\n",
    "\n",
    "# delphes\n",
    "#f = \"../data/w-vs-qcd/anti-kt/antikt-delphes-train.pickle\"\n",
    "f = \"../data/w-vs-qcd/anti-kt/antikt-delphes-test.pickle\"\n",
    "\n",
    "fd = open(f, \"rb\")\n",
    "X, y = pickle.load(fd)\n",
    "fd.close()\n",
    "\n",
    "# anti-kt highest pt -> preprocessing -> kt\n",
    "X_ = []\n",
    "\n",
    "for j in X:\n",
    "    X_.append(randomize(preprocess(j, output=\"anti-kt\"))\n",
    "    \n",
    "fd = open(\"%s-random\" % f, \"wb\")\n",
    "pickle.dump((X_, y), fd, protocol=2)\n",
    "fd.close()\n",
    "\n",
    "X_ = []\n",
    "\n",
    "for j in X:\n",
    "    X_.append(sequentialize_by_pt(preprocess(j, output=\"anti-kt\"), reverse=False))\n",
    "    \n",
    "fd = open(\"%s-seqpt\" % f, \"wb\")\n",
    "pickle.dump((X_, y), fd, protocol=2)\n",
    "fd.close()\n",
    "\n",
    "X_ = []\n",
    "\n",
    "for j in X:\n",
    "    X_.append(sequentialize_by_pt(preprocess(j, output=\"anti-kt\"), reverse=True))\n",
    "    \n",
    "fd = open(\"%s-seqpt-reversed\" % f, \"wb\")\n",
    "pickle.dump((X_, y), fd, protocol=2)\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# event-level\n",
    "import pickle\n",
    "\n",
    "# f = \"../data/w-vs-qcd/anti-kt/antikt-event-train.pickle\"\n",
    "# f = \"../data/w-vs-qcd/anti-kt/antikt-event-test.pickle\"\n",
    "# f = \"../data/w-vs-qcd/anti-kt/antikt-delphes-event-train.pickle\"\n",
    "f = \"../data/w-vs-qcd/anti-kt/antikt-delphes-event-test.pickle\"\n",
    "\n",
    "fd = open(f, \"rb\")\n",
    "fd_out = open(\"%s-kt\" % f, \"wb\")\n",
    "\n",
    "for i in range(20000):\n",
    "    try:\n",
    "        event, y = pickle.load(fd)\n",
    "        jets = [(j[\"phi\"], j[\"eta\"], j[\"pt\"], j[\"mass\"], preprocess(j, output=\"kt\")) for j in event]\n",
    "        pickle.dump((jets, y), fd_out, protocol=2)\n",
    "    except IndexError:\n",
    "        print(i)\n",
    "\n",
    "fd.close()\n",
    "fd_out.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = open(\"../data/w-vs-qcd/final/antikt-kt-test.pickle\", \"rb\")\n",
    "X, y = pickle.load(fd)\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (6,6)\n",
    "from rootpy.vector import LorentzVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "\n",
    "for j in X[10000:]:\n",
    "    constituents = j[\"content\"][j[\"tree\"][:, 0] == -1]\n",
    "    a.append(np.array([[LorentzVector(c).eta(), \n",
    "                        LorentzVector(c).phi()] for c in constituents]))\n",
    "    \n",
    "a = np.vstack(a)\n",
    "\n",
    "plt.hist2d(a[:, 0], a[:, 1], range=[(-2,2), (-2,2)], \n",
    "           bins=50, cmap=\"hsv\", norm=LogNorm())\n",
    "plt.show()\n",
    "\n",
    "a = []\n",
    "\n",
    "for j in X[:10000]:\n",
    "    constituents = j[\"content\"][j[\"tree\"][:, 0] == -1]\n",
    "    a.append(np.array([[LorentzVector(c).eta(), \n",
    "                        LorentzVector(c).phi()] for c in constituents]))\n",
    "    \n",
    "a = np.vstack(a)\n",
    "\n",
    "plt.hist2d(a[:, 0], a[:, 1], range=[(-2,2), (-2,2)], \n",
    "           bins=50, cmap=\"hsv\", norm=LogNorm())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repartition into 100k train / 100k test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import check_random_state\n",
    "\n",
    "# prefixes = [\"antikt-antikt\", \"antikt-antikt-trimmed\",\n",
    "#             \"antikt-cambridge\", \"antikt-kt-delphes\",\n",
    "#             \"antikt-kt-images\", \"antikt-kt\", \"antikt-kt-trimmed\",\n",
    "#             \"antikt-random\", \"antikt-seqpt\", \"antikt-kt-soft\",\n",
    "#             \"antikt-kt-colinear1\", \"antikt-kt-colinear10\",\n",
    "#             \"antikt-antikt-delphes\", \"antikt-seqpt-delphes\", \"antikt-random-delphes\", \n",
    "#             \"antikt-cambridge-delphes\", \"antikt-seqpt-reversed\", \"antikt-seqpt-reversed-delphes\", \"antikt-kt-colinear1-max\"]\n",
    "\n",
    "prefixes = [\"antikt-kt-colinear10-max\"]\n",
    "\n",
    "for prefix in prefixes:\n",
    "    print(prefix)\n",
    "\n",
    "    filename_train = \"../data/w-vs-qcd/final/%s-train.pickle\" % prefix\n",
    "    filename_test = \"../data/w-vs-qcd/final/%s-test.pickle\" % prefix\n",
    "\n",
    "    fd = open(filename_train, \"rb\")\n",
    "    X1, y1 = pickle.load(fd)\n",
    "    fd.close()\n",
    "\n",
    "    fd = open(filename_test, \"rb\")\n",
    "    X2, y2 = pickle.load(fd)\n",
    "    fd.close()\n",
    "\n",
    "    rng = check_random_state(1)\n",
    "    indices = rng.permutation(len(X1))\n",
    "\n",
    "    X_train = [X1[j] for j in indices[:100000]]\n",
    "    y_train = [y1[j] for j in indices[:100000]]\n",
    "    X_test = [X1[j] for j in indices[100000:]]\n",
    "    X_test.extend(X2)\n",
    "    y_test = [y1[j] for j in indices[100000:]]\n",
    "    y_test.extend(y2)\n",
    "\n",
    "    print(len(X_train), len(y_train))\n",
    "    print(len(X_test), len(y_test))\n",
    "\n",
    "    fd = open(filename_train, \"wb\")\n",
    "    pickle.dump((X_train, y_train), fd, protocol=2)\n",
    "    fd.close()\n",
    "\n",
    "    fd = open(filename_test, \"wb\")\n",
    "    pickle.dump((X_test, y_test), fd, protocol=2)\n",
    "    fd.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
